---
title: "CMSC 320 Final Project"
author: "Jacob Luterman, Joshua Pooranmal, Shiv Patel"
date: "05/18/2020"
output: html_document
---

Music has the power to culturally, morally, and emotionally influence our society. As time progresses, and popular culture inevitably shifts, diffrent genres of music begin to surface and become popular. Whether it's 1940s swing, 1970s rock-and-roll, or 1990s hip-hop, society's ear for music is constantly changing. In order for record labels (both old and new) to maintain relevance and continue to be proftable, it is important to have some way of keeping up with contemporary society's musical preferences. Playing it by ear is seems like a good idea, but this introduces a lot of subjectivity, which isn't reliable. Tracking user feedback is also a good idea if you're looking to gauge how well a song is currently doing, but the point is to stay ahead of the game, not alongside it. 

So how does one work to predict whether or not a song will be a hit? 

The following 


```{r results='hide', message=FALSE, warning=FALSE}
library(rvest)
library(tidyverse)
library(lubridate)
library(tidymodels)
library(caret) # Confusion matrix, algorithm training
library(mice) # Basic data preprocessing - eg. Removing null values(na.omit)etc
library(ggplot2) # All plots
library(ggcorrplot) # All correlation plot
library(dplyr) # For data manipulation .. eg. selecting numeric variables)
library(openxlsx) # read excel file
library(knitr)
options(stringsAsFactors = FALSE)

# Datasets retrieved from https://www.kaggle.com/theoverman/the-spotify-hit-predictor-dataset
songs_2010 <- "dataset-of-10s.csv"
songs_2000 <- "dataset-of-00s.csv"
songs_1990 <- "dataset-of-90s.csv"
songs_1980 <- "dataset-of-80s.csv"
songs_1970 <- "dataset-of-70s.csv"
songs_1960 <- "dataset-of-60s.csv"
```


```{r}
song_files <- c(songs_2010,songs_2000,songs_1990,songs_1980,songs_1970,songs_1960)
song_df <- NULL
for (song_file in song_files) {
  tmp_df <- read.csv(song_file)
  decade <- str_extract(song_file,"\\d{2}")
  tmp_df$decade <- decade
  song_df <- bind_rows(song_df,tmp_df)
}
song_df$decade <- ordered(song_df$decade, levels = c("60","70","80","90","00","10"))

as_tibble(song_df)
```
The code chunk above takes music datasets from the 1960's, 1970's, 1980's, 1990's, 2000's, and 2010's and puts it together to make a larger dataframe containg all songs from all of the datasets. In addition the column "decade" is added containing the decade of each song. This is relevant for the rest of the PROJECT??? since it will allow us to see various aspects of each decade throughout. 


```{r graph}
song_df <- song_df %>% 
  select(-c(uri,key,valence,track))

as_tibble(song_df)
```
This code chunk is used to get rid of elements of the dataset that are not relevant to this. uri which is the url is not relevant to this as the key song and valence is not relevent ADD STUFF?. track and artist are strings meaning we can't use this in analyzing the data. However, if we wanted to see if there is a different chance for an artist to have a hit given that they have had one previously we could use this. (We would find the first instance of when the artist had a hit and come up with a formula that way)

```{r}
hits_only <- filter(song_df,target == 1) 

as_tibble(hits_only)
```

```{r tempo}
plot_avg_by_decade <- function(df,col){
  
plotting <- df %>% 
  group_by(decade,target) %>% 
  summarise(avg=mean({{col}})) %>% 
  mutate(target=as.factor(target))

  ggplot(plotting) + 
    geom_bar(stat="identity", aes(x=decade,y = avg,fill=target), position = "dodge") +
    labs(title = "Tempo Changes per Decade Between Hits(1) and Non-Hits(0)", x = "Decade", y = "Average Tempo") +
    theme(plot.title = element_text(hjust = 0.5)) 
}

song_df %>% 
  plot_avg_by_decade(tempo)
```
The code chunk above looks to compare average tempo between songs that were hits in each decade which is represented by the red color with all songs that were not hits in each decade which is represented by the color blue. Based off of the graph it does not seem that there is a differrence in the tempo between songs that are hits and songs that are not.



```{r energy}
plot_avg_by_decade <- function(df,col){
  
plotting <- df %>% 
  group_by(decade,target) %>% 
  summarise(avg=mean({{col}})) %>% 
  mutate(target=as.factor(target))

  ggplot(plotting) + 
    geom_bar(stat="identity", aes(x=decade,y = avg,fill=target), position = "dodge") +
    labs(title = "Energy Changes per Decade Between Hits(1) and Non-Hits(0)", x = "Decade", y = "Average Energy") +
    theme(plot.title = element_text(hjust = 0.5)) 
}

song_df %>% 
  plot_avg_by_decade(energy)
```
energy

```{r acousticness}
plot_avg_by_decade <- function(df,col) {
  
  plotting <- df %>% 
    group_by(decade,target) %>% 
    summarise(avg=mean({{col}})) %>% 
    mutate(target=as.factor(target))
  
  ggplot(plotting) + 
    geom_bar(stat="identity", aes(x=decade,y = avg,fill=target), position = "dodge") +
    labs(title = "Acousticness Changes per Decade Between Hits(1) and Non-Hits(0)", x = "Decade", y = "Average Acousticness") +
    theme(plot.title = element_text(hjust = 0.5)) 
}

song_df %>% 
  plot_avg_by_decade(acousticness)
```
acousticness

```{r liveliness}
plot_avg_by_decade <- function(df,col){
  
  plotting <- df %>% 
    group_by(decade,target) %>% 
    summarise(avg=mean({{col}})) %>% 
    mutate(target=as.factor(target))
  
  ggplot(plotting) + 
    geom_bar(stat="identity", aes(x=decade,y = avg,fill=target), position="dodge") +
    labs(title = "Liveliness Changes per Decade Between Hits(1) and Non-Hits(0)", x = "Decade", y = "Average Liveliness") +
    theme(plot.title = element_text(hjust = 0.5)) 
}

song_df %>% 
  plot_avg_by_decade(liveness)
```
livenss

```{r durationms}
plot_avg_by_decade <- function(df,col){
  
  plotting <- df %>% 
    group_by(decade,target) %>% 
    summarise(avg=mean({{col}})) %>% 
    mutate(target=as.factor(target))
  
  ggplot(plotting) + 
    geom_bar(stat="identity", aes(x=decade,y = avg,fill=target), position ="dodge") +
    labs(title = "Duration(ms) Changes per Decade Between Hits(1) and Non-Hits(0)", x = "Decade", y = "Average Duration(ms)") +
    theme(plot.title = element_text(hjust = 0.5)) 
}

song_df %>% 
  plot_avg_by_decade(duration_ms)
```
duration

```{r timesignature}
plot_avg_by_decade <- function(df,col){
  
  plotting <- df %>% 
    group_by(decade,target) %>% 
    summarise(avg=mean({{col}})) %>% 
    mutate(target=as.factor(target))
  
  ggplot(plotting) + 
    geom_bar(stat= "identity",aes(x=decade,y = avg,fill=target),position = "dodge") +
    labs(title = "Time Signature Changes per Decade Between Hits(1) and Non-Hits(0)", x = "Decade", y = "Average Time Signature") +
    theme(plot.title = element_text(hjust = 0.5)) 
}

song_df %>% 
  plot_avg_by_decade(time_signature)
```
time signature

```{r chorushit}
plot_avg_by_decade <- function(df,col){
  
  plotting <- df %>% 
    group_by(decade,target) %>% 
    summarise(avg=mean({{col}})) %>% 
    mutate(target=as.factor(target))
  
  ggplot(plotting) + 
    geom_bar(stat="identity", aes(x=decade,y = avg,fill=target), position="dodge") +
    labs(title = "Chorous Hit Changes per Decade Between Hits(1) and Non-Hits(0)", x = "Decade", y = "Average Chorus Hit") +
    theme(plot.title = element_text(hjust = 0.5)) 
}

song_df %>%
  plot_avg_by_decade(chorus_hit)
```
chorus

```{r sections}
plot_avg_by_decade <- function(df,col){
  
  plotting <- df %>% 
    group_by(decade,target) %>% 
    summarise(avg=mean({{col}})) %>% 
    mutate(target=as.factor(target))
  
  ggplot(plotting) + 
    geom_bar(stat="identity", aes(x=decade,y = avg,fill=target), position = "dodge") +
    labs(title = "Sections Changes per Decade Between Hits(1) and Non-Hits(0)", x = "Decade", y = "Average Sections") +
    theme(plot.title = element_text(hjust = 0.5)) 
}

song_df %>% 
  plot_avg_by_decade(sections)
```
sections

```{r loudness}
plot_avg_by_decade <- function(df,col){
  
  plotting <- df %>% 
    group_by(decade,target) %>% 
    summarise(avg=mean({{col}})) %>% 
    mutate(target=as.factor(target))
  
  ggplot(plotting) + 
    geom_bar(stat="identity", aes(x=decade,y = avg,fill=target), position="dodge") +
    labs(title = "Loudness Changes per Decade Between Hits(1) and Non-Hits(0)", x = "Decade", y = "Average Loudness") +
    theme(plot.title = element_text(hjust = 0.5)) 
}

song_df %>% 
  plot_avg_by_decade(loudness)
```
loudness

```{r speechiness}
plot_avg_by_decade <- function(df,col){
  
  plotting <- df %>% 
    group_by(decade,target) %>% 
    summarise(avg=mean({{col}})) %>% 
    mutate(target=as.factor(target))
  
  ggplot(plotting) + 
    geom_bar(stat= "identity",aes(x=decade,y = avg,fill=target),position = "dodge") +
    labs(title = "Speechiness Changes per Decade Between Hits(1) and Non-Hits(0)", x = "Decade", y = "Average Spechiness") +
    theme(plot.title = element_text(hjust = 0.5)) 
}

song_df %>% 
  plot_avg_by_decade(speechiness)
```
speechness

```{r instrumentalness}
plot_avg_by_decade <- function(df,col){
  
  plotting <- df %>% 
    group_by(decade,target) %>% 
    summarise(avg=mean({{col}})) %>% 
    mutate(target=as.factor(target))
  
  ggplot(plotting) + 
    geom_bar(stat="identity", aes(x=decade,y = avg,fill=target), position="dodge") +
    labs(title = "Instrumentalness Changes per Decade Between Hits(1) and Non-Hits(0)", x = "Decade", y = "Average Instrumentalness") +
    theme(plot.title = element_text(hjust = 0.5)) 
}

song_df %>% 
  plot_avg_by_decade(instrumentalness)
```
intstrumentalness
how many artists have hits

```{r}
song_df %>% 
  group_by(decade) %>%
  count -> freq
  ggplot(freq) + geom_bar(stat= "identity",aes(x=decade,y = n),position = "dodge")


```
#how many songs in each decade



```{r}
plot_total_hits_by_decade <- function(df,col){
  
  plotting <- df %>% group_by(decade) %>% 
    summarise(hits=sum({{col}}))
  ggplot(plotting) + geom_bar(stat= "identity",aes(x=decade,y = hits))
}
song_df %>% plot_total_hits_by_decade(target)





```
hits per decade
This graph looks at the total amount of hits per decade. This is relevant because it shows that there was more variance in terms of how many different songs were hits. Leads to questions of how many different artists had hits to see if popularity of artists determined the amount of hits.


random forest 
new chunk to prevent the constant running of previous chunk
based off of our predictions we have an 80% accuracy on unseen data

```{r}
song_df %>% 
  select(-c(artist,mode,sections,time_signature)) %>% 
  mutate(target = as.factor(target))-> update_song_df
  training_data <- update_song_df %>% 
    filter(decade!="10")
  testing_data <- update_song_df %>% 
     filter(decade=="10")
data_recipe <- training_data %>% recipe(target~.) %>% 
  step_corr(all_numeric()) %>% 
  step_center(all_numeric(),-all_outcomes()) %>% 
  step_scale(all_numeric(),-all_outcomes()) %>% 
  prep()

data_testing <- data_recipe %>% 
  bake(testing_data)
data_training <- juice(data_recipe)

```
filteres specific entities. Using tidymodel, 

Training data: 60s - 00s
Test data: 10s

Recipe is data preprocessing

everything else is making sure that data is being procesed correctly


```{r}
r_forest <- rand_forest(trees = 100, mode = "classification") %>% 
  set_engine("randomForest") %>% 
  fit(target~., data = data_training)

r_forest %>%
  predict(data_testing) %>% 
  bind_cols(data_testing) -> predictions_r_forest
  predictions_r_forest %>% 
    metrics(truth = target,estimate = .pred_class)
```
Using random forest

Assertion: based off of a random forst model with 100 trees, there is a 79% accuracy. 

## Multiple Logistic Regression

```{r}

mus = read.csv("song_df.csv") #read song dataset to variable mus



musiclog = mus[,-c(1,2,3,4)]#removing the  X ,track,artist,uri as these cannot be modelled

#summary of dataset
summary(musiclog) 
```


## Correlation Analysis

```{r }

musiclognum = musiclog%>% select_if(is.numeric)#selecting only the numeric variables from student for correlation

#Correlation plot from numeric variables
ggcorrplot(cor(musiclognum), hc.order = TRUE, outline.col = "white",lab = TRUE, title = "Correlation Plot", insig = c("pch", "blank"), pch = 4, pch.col = "black",lab_size = 2,tl.cex =8)
```

The correlation plot helps showcase the relationship between numeric variables. instrumentalness variable has the highest correlation(.41) with the Target variable, followed by danceability.



## Logistic Regression Model

```{r }
musiclog$decade = as.factor(musiclog$decade)#converting decade variable to factor
set.seed(123)#used to randomize the records in the dataset

train_set <- musiclog %>% filter(decade != "0" & decade != "10" )#training set obtained by filtering on data below 2000
train_set <-train_set[,-c(17)]

test_set <- filter(musiclog, decade == "0" | decade == "10")#testing set obtained by filtering on data from 2000 till now
test_set <-test_set[,-c(17)]

```

```{r}
logitreg <- glm(target~.,data = train_set, family = "binomial")#Creating a logistic regression model based on all the independent variables
  
#Model summary
summary(logitreg)
```

```{r}
predicttrain <- predict(logitreg,test_set,type = "response")#generating predicted output as a probability


Predicted_Result <- as.factor(ifelse(predicttrain > .6,1,0))#checking if predicted output is greater than 60% threshold and then assigning the target class(1/0)

#confusion matrix b/w predicted output and test data output
confusionMatrix(table(Predicted = Predicted_Result,Actual = test_set$target),positive = "1")
```


A logistic regression model was created based on all the independant variables and the dependant variable Target(1/0).  
From the model summary it is clear that at 95% confidence interval all the independendant variables except - valence,time_signature and duration_ms were statistically significant in determining the Target(1/0). This was confirmed as the variables had p-value less than 0.05 thus rejecting the null hypothesis that coefficient = 0.

By keeping the cutoff for the Target variable to be considered as hit to .6 , a confusion matrix was created. The confusion matrix shows the model has an accuracy of 74.56% which is greater than the No - information rate. The confusion matrix also shows the sensitivity(82.46%) and specificity(66.6%) for the model.


## Variable Importance as Per T-Statistic

```{r }

#Creating a data frame showing variable importance in decreasing order of importnace based on T-statistic
imp <- as.data.frame(varImp(logitreg))
imp <- data.frame(Variable_names   = rownames(imp),overall_Importance_Tstat = imp$Overall)
imp[order(imp$overall,decreasing = T),]

```


```{r breakoutvsnon}
song_df %>% 
  group_by(decade,artist) %>%
  summarise(has_hit=max(target))%>%
  mutate(has_hit=as.factor(has_hit)) %>% 
  group_by(decade,has_hit)%>% 
  count -> hit_amount 

ggplot(hit_amount) + 
  geom_bar(stat="identity", aes(x=decade,y=n,fill=has_hit), position="dodge") +
  labs(title = "Hits per Decade Between Breakout Artists(0) and Artists with Existing Hits(1)", x = "Decade", y = "Number of Hits") +
  theme(plot.title = element_text(hjust = 0.5)) 
```


```{r}
song_df %>% 
  group_by(decade,artist) %>%
  summarise(num_hits=sum(target))%>%
  mutate(hit_range=cut(num_hits,c(0,1,2,5,11,21,31,41,75),right=FALSE,include.lowest = TRUE))%>% 
  group_by(decade,hit_range)%>% 
  count -> tot_hit
ggplot(tot_hit) + geom_bar(stat="identity", aes(x=decade,y=n,fill=hit_range),position = "dodge")
  
# %of hits from artists who already have one vs % of hits from those who don't(total artists with hits vs total hits starting from the second hit) --> try 

#artist likelihood of having a previous hit affect liklihood of another song becoming a hit (when does the "takeoff happen) #how many hit songs (does it exponentially increase chances of having more) graph of total amount of hits vs how many artists have that many hits
```
#compares growth between ranges of hits. seeing how many hits an artist needs before they reach a certain amount of hits --> Stardom? break up this data more to get better precentages for determining the tipping point between "guaranteed hit"



#shows how many artists had how many hits on ranges in each decade.

```{r}
song_df %>% 
  group_by(decade,artist) %>%
  summarise(num_hits=sum(target))%>%
  mutate(hit_range=cut(num_hits,c(0,1,2,5,10,15,20,25,30,35,40,45,50,55,60,65,70,75),right=FALSE,include.lowest = TRUE))%>% 
  group_by(decade,hit_range)%>% 
  summarise(n=n()) %>% 
  ungroup() -> mid_df

hit_ranges <- mid_df %>% ungroup() %>%
  distinct(hit_range) %>%
  mutate(join_var = 1)

decades <- mid_df %>% 
  distinct(decade) %>% 
  arrange(decade) %>% mutate(join_var = 1)
all_combo <- hit_ranges %>% 
  inner_join(decades,by = "join_var") %>% 
  select(-join_var)

all_combo %>% 
  left_join(mid_df,by = c("decade","hit_range")) %>% 
  replace_na(list(n=0)) %>% 
  group_by(decade) %>% 
  arrange(hit_range) %>% 
  mutate(freq = n/sum(n),cum_freq = rev(cumsum(rev(freq)))) %>% 
  ungroup() -> per_df
  
  
decades <- per_df %>% 
  distinct(decade) %>% 
  arrange(decade) %>% 
  unlist() %>% 
  unname()

plot_lst = list()
for (dec in decades) {
  plot_lst [[dec]] <- ggplot(per_df %>% filter(decade == dec)) + geom_bar(aes(x = hit_range,y=cum_freq), stat = "identity") + ggtitle(dec)
}
plot_lst[["60"]]
plot_lst[["70"]]
plot_lst[["80"]]
plot_lst[["90"]]
plot_lst[["00"]]
plot_lst[["10"]]
```
#total hits in each decade will divide each entity going up showing percentages 

#if artist already has a hit go in 'b' else 'a'


```{r}



#machine learning model for predicting hits, or determining how a song would become a hit (XGB, logistic regression(linear) determines what variables are importantnt for making hits, or random forest--non linear)






#different formula potentially for first hit vs afterwards like lets say the song hit #40 would that change if the song was #1 or #100



#after training models look for equivalent dataset to see if there is something for 2020 so far

#https://www.kaggle.com/theoverman/the-spotify-hit-predictor-dataset
#https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-features/
#https://towardsdatascience.com/song-popularity-predictor-1ef69735e380
#might need to scrape billboard top 100 to get the list of songs we need to test -> what about the other elements

#https://github.com/manasreldin/Song-Popularity-Predictor/blob/master/Scrape_BB.ipynb -> datascrape billbaord

#https://github.com/manasreldin/Song-Popularity-Predictor/blob/master/demo.py

#https://github.com/manasreldin/Song-Popularity-Predictor/blob/master/SimpleFeatures.csv

#https://github.com/manasreldin/Song-Popularity-Predictor/blob/master/PredictHotBB.ipynb
```
As a result of there not being any significant data to suggest whether or not there is a a difference between tempo we test other aspects of the dataframe to see if there are any indictors to show separation between songs that are hits and songs that are not.




